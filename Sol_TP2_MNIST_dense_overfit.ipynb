{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning avec les modules Python tensorflow2/keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrôler l'*over-fit* d'entraînement par le *Early stopping* \n",
    "\n",
    "\n",
    "Ce notebook montre comment mettre en oeuvre le `callback` tensorflow `Early Stopping` pour éviter le sur-entraînement d'un réseau.\n",
    "\n",
    "Documentation à consulter : page [tf.keras.callbacks.EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environnement Python de travail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<span style=\"color:brown;font-family:arial;font-size:normal\"> \n",
    "L'état de l'art actuel des projets de machine learning sous Python préconise l'utilisation d'un <span style=\"font-weight:bold;\">environnement virtuel Python3</span> qui permet de maîtriser pour chaque projet les versions des modules Python \"sensibles\" (comme tensorflow par xemple) : dans le cas d'un démarrage de l'ordinateur avec une clef USB Ubuntu, on peut considérer que la clef fournit un environnement Python dédié  (celui de la clef), à condition de ne pas faire de mises à jour des paquets Python avec <span style=\"font-style:italic\">pip install...</span>\n",
    "    \n",
    "Dans le cas contraire, le document <span style=\"font-style:italic\">EnvironnementPython_tf2.pdf</span> explique comment créer un environnement Python dédié pour le travail avec le module tensorflow.\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation tensorflow/keras\n",
    "\n",
    "Le module **keras** qui permet une manipulation de haut niveau des objets **tensorflow** est intégré dans tensorflow2. La documentation du module **tf.keras** à consulter pour ce TP est ici : https://www.tensorflow.org/api_docs/python/tf/keras. \n",
    "\n",
    "Vérification des versions des modules Python validées pour ce TP sous Ubuntu 20 :\n",
    "- Python 3.8.5\n",
    "- tensorflow 2.4.0 incluant tensorflow.keras 2.4.0\n",
    "- OpenCV 4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys, cv2\n",
    "print(f\"Python    : {sys.version.split()[0]}\")\n",
    "print(f\"tensorflow: {tf.__version__} incluant keras {keras.__version__}\")\n",
    "print(f\"OpenCV    : {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incrustation des tracés matplotlib dans le cahier IPython et import de modules utiles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/ Récupération et prétraitement des images MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(im_train, lab_train), (im_test, lab_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# 1/ Récupèrer le nombre d'images d'entrainement, de test et le nombre de pixels des images:\n",
    "nb_im_train = im_train.shape[0]\n",
    "nb_im_test  = im_test.shape[0]\n",
    "nb_pixels   = im_train[0].size        # normalement : 28 x 28 = 784 pixels\n",
    "print(f\"{nb_im_train} images d'entraînement et {nb_im_test} images de test\")\n",
    "print(f\"{nb_pixels} pixels dans chaque image\")\n",
    "\n",
    "# 2/ Mettre 'à plat' des matrices sous forme de vecteurs de floats normalisés dans [0., 1.]: \n",
    "x_train = im_train.reshape((nb_im_train, nb_pixels))/255.\n",
    "x_test  = im_test.reshape((nb_im_test, nb_pixels))/255\n",
    "\n",
    "# 3/ 'one-hot encoding' des sorties:\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(lab_train)\n",
    "y_test  = to_categorical(lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B/ Entraîner le réseau en arrêtant avant l'*over-fit*\n",
    "\n",
    "On reprend le même réseau que dans le TP1, mais on utilise keras pour arrêter automatiquement l'apprentissage en surveillant par exemple la croissance de la précision d'une `epoch` à l'autre. \n",
    "\n",
    "Le mécanisme consiste à définir des fonction *callback* qui sont utilisées par Keras lors de l'entraînnement grâce à l'agument nommé  `callback` :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction du réseau dense :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "nb_classes = 10\n",
    "np.random.seed(43)\n",
    "\n",
    "# les 5 lignes pour construire le réseau de neurones:\n",
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(nb_pixels,)))\n",
    "model.add(Dense(nb_pixels, activation='relu'))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement avec contrôle de l'over-fit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callbacks_list = [\n",
    "    EarlyStopping(monitor='val_accuracy',  # la grandeur à surveiller\n",
    "                  patience=2,              # on accepte que 'val_accuracy' puisse diminuer 2 fois de suite\n",
    "                  verbose=1)\n",
    "]\n",
    "\n",
    "# recharger les valeurs initiasles des poids du réseau:\n",
    "model.load_weights(\"weights/initial\")\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                 epochs=15, \n",
    "                 batch_size=128, \n",
    "                 callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noter l'arrêt avec le message **early stopping**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import plot_loss_accuracy\n",
    "plot_loss_accuracy(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
